{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a7a34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Gender Detection System...\n",
      "Loading YOLO model...\n",
      "Loading face detector...\n",
      "Models loaded successfully!\n",
      "System ready! Press 'q' to quit, 'p' to switch modes\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "class GenderDetection:\n",
    "    def __init__(self):\n",
    "        # Load YOLOv8 model for person detection\n",
    "        print(\"Loading YOLO model...\")\n",
    "        self.yolo_model = YOLO('yolov8n.pt')\n",
    "       \n",
    "        # Initialize Haar Cascade for face detection (built into OpenCV)\n",
    "        print(\"Loading face detector...\")\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "       \n",
    "        # Gender classes\n",
    "        self.gender_classes = ['Male', 'Female']\n",
    "       \n",
    "        # Age ranges\n",
    "        self.age_ranges = ['Child (0-12)', 'Teen (13-19)', 'Young Adult (20-30)',\n",
    "                          'Adult (31-50)', 'Middle-aged (51-65)', 'Senior (65+)']\n",
    "       \n",
    "        # Colors for visualization\n",
    "        self.colors = {'Male': (255, 0, 0), 'Female': (255, 20, 147)}\n",
    "        self.age_colors = {\n",
    "            'Child (0-12)': (0, 255, 255),      # Cyan\n",
    "            'Teen (13-19)': (255, 255, 0),       # Yellow\n",
    "            'Young Adult (20-30)': (0, 255, 0),  # Green\n",
    "            'Adult (31-50)': (255, 165, 0),      # Orange\n",
    "            'Middle-aged (51-65)': (255, 0, 255), # Magenta\n",
    "            'Senior (65+)': (128, 0, 128)        # Purple\n",
    "        }\n",
    "       \n",
    "        print(\"Models loaded successfully!\")\n",
    "   \n",
    "    def detect_people_yolo(self, frame):\n",
    "        \"\"\"Detect people using YOLO\"\"\"\n",
    "        results = self.yolo_model(frame, classes=[0], verbose=False)  # class 0 is person\n",
    "        people_boxes = []\n",
    "       \n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            if boxes is not None:\n",
    "                for box in boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "                    conf = box.conf[0].cpu().numpy()\n",
    "                   \n",
    "                    if conf > 0.5:  # Confidence threshold\n",
    "                        people_boxes.append([x1, y1, x2, y2, conf])\n",
    "       \n",
    "        return people_boxes\n",
    "   \n",
    "    def detect_faces_haar(self, frame):\n",
    "        \"\"\"Detect faces using Haar Cascade\"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(50, 50))\n",
    "       \n",
    "        face_boxes = []\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_boxes.append([x, y, x+w, y+h, 0.8])  # Adding dummy confidence\n",
    "       \n",
    "        return face_boxes\n",
    "   \n",
    "    def analyze_facial_features(self, face_crop):\n",
    "        \"\"\"Analyze facial features for gender and age classification\"\"\"\n",
    "        if face_crop.size == 0:\n",
    "            return 'Unknown', 0.5, 'Unknown', 0.5\n",
    "       \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(face_crop, cv2.COLOR_BGR2GRAY)\n",
    "        h, w = gray.shape\n",
    "       \n",
    "        if h < 50 or w < 50:\n",
    "            return 'Unknown', 0.5, 'Unknown', 0.5\n",
    "       \n",
    "        # Feature extraction\n",
    "        features = self.extract_features(gray, face_crop)\n",
    "       \n",
    "        # Classification based on features\n",
    "        gender, gender_conf = self.classify_gender_by_features(features)\n",
    "        age_range, age_conf = self.classify_age_by_features(features)\n",
    "       \n",
    "        return gender, gender_conf, age_range, age_conf\n",
    "   \n",
    "    def extract_features(self, gray_face, color_face):\n",
    "        \"\"\"Extract comprehensive features from face\"\"\"\n",
    "        features = {}\n",
    "       \n",
    "        # Face dimensions\n",
    "        h, w = gray_face.shape\n",
    "        features['aspect_ratio'] = w / h if h > 0 else 1\n",
    "        features['face_area'] = h * w\n",
    "       \n",
    "        # Divide face into regions\n",
    "        upper_half = gray_face[:h//2, :]\n",
    "        lower_half = gray_face[h//2:, :]\n",
    "       \n",
    "        # Eye area (upper third)\n",
    "        eye_area = gray_face[:h//3, :]\n",
    "       \n",
    "        # Jaw area (lower third)\n",
    "        jaw_area = gray_face[2*h//3:, :]\n",
    "       \n",
    "        # Forehead area (top quarter)\n",
    "        forehead_area = gray_face[:h//4, :]\n",
    "       \n",
    "        # Calculate intensity variations (texture)\n",
    "        features['upper_variance'] = np.var(upper_half)\n",
    "        features['lower_variance'] = np.var(lower_half)\n",
    "        features['jaw_variance'] = np.var(jaw_area) if jaw_area.size > 0 else 0\n",
    "        features['eye_variance'] = np.var(eye_area) if eye_area.size > 0 else 0\n",
    "        features['forehead_variance'] = np.var(forehead_area) if forehead_area.size > 0 else 0\n",
    "       \n",
    "        # Edge detection for feature sharpness\n",
    "        edges = cv2.Canny(gray_face, 50, 150)\n",
    "        features['edge_density'] = np.sum(edges) / (h * w)\n",
    "       \n",
    "        # Regional edge density\n",
    "        upper_edges = edges[:h//2, :]\n",
    "        lower_edges = edges[h//2:, :]\n",
    "        features['upper_edge_density'] = np.sum(upper_edges) / upper_edges.size\n",
    "        features['lower_edge_density'] = np.sum(lower_edges) / lower_edges.size\n",
    "       \n",
    "        # Histogram features\n",
    "        hist = cv2.calcHist([gray_face], [0], None, [256], [0, 256])\n",
    "        features['hist_peak'] = np.argmax(hist)\n",
    "        features['hist_spread'] = np.std(hist)\n",
    "        features['brightness_mean'] = np.mean(gray_face)\n",
    "       \n",
    "        # Wrinkle detection (high frequency content)\n",
    "        features['wrinkle_score'] = self.detect_wrinkles(gray_face)\n",
    "       \n",
    "        # Skin texture analysis\n",
    "        features['skin_smoothness'] = self.analyze_skin_texture(color_face)\n",
    "       \n",
    "        # Face symmetry\n",
    "        features['symmetry_score'] = self.calculate_symmetry(gray_face)\n",
    "       \n",
    "        # Regional brightness variations\n",
    "        features['brightness_variation'] = np.std([\n",
    "            np.mean(eye_area),\n",
    "            np.mean(jaw_area),\n",
    "            np.mean(forehead_area)\n",
    "        ])\n",
    "       \n",
    "        return features\n",
    "   \n",
    "    def detect_wrinkles(self, gray_face):\n",
    "        \"\"\"Detect wrinkles and fine lines for age estimation\"\"\"\n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blurred = cv2.GaussianBlur(gray_face, (3, 3), 0)\n",
    "       \n",
    "        # Use Laplacian to detect fine details (wrinkles)\n",
    "        laplacian = cv2.Laplacian(blurred, cv2.CV_64F)\n",
    "       \n",
    "        # Calculate wrinkle score\n",
    "        wrinkle_score = np.var(laplacian)\n",
    "       \n",
    "        return wrinkle_score\n",
    "   \n",
    "    def analyze_skin_texture(self, color_face):\n",
    "        \"\"\"Analyze skin texture for age estimation\"\"\"\n",
    "        # Convert to LAB color space for better skin analysis\n",
    "        lab = cv2.cvtColor(color_face, cv2.COLOR_BGR2LAB)\n",
    "        l_channel = lab[:, :, 0]  # Lightness channel\n",
    "       \n",
    "        # Calculate local binary pattern-like texture measure\n",
    "        kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]])\n",
    "        texture_response = cv2.filter2D(l_channel, -1, kernel)\n",
    "       \n",
    "        # Smoothness score (inverse of texture variation)\n",
    "        smoothness = 1.0 / (1.0 + np.var(texture_response))\n",
    "       \n",
    "        return smoothness\n",
    "   \n",
    "    def calculate_symmetry(self, gray_face):\n",
    "        \"\"\"Calculate face symmetry\"\"\"\n",
    "        h, w = gray_face.shape\n",
    "       \n",
    "        # Split face vertically\n",
    "        left_half = gray_face[:, :w//2]\n",
    "        right_half = gray_face[:, w//2:]\n",
    "       \n",
    "        # Flip right half\n",
    "        right_flipped = cv2.flip(right_half, 1)\n",
    "       \n",
    "        # Resize to match if needed\n",
    "        min_width = min(left_half.shape[1], right_flipped.shape[1])\n",
    "        left_resized = left_half[:, :min_width]\n",
    "        right_resized = right_flipped[:, :min_width]\n",
    "       \n",
    "        # Calculate similarity (symmetry)\n",
    "        if left_resized.shape == right_resized.shape:\n",
    "            difference = np.abs(left_resized.astype(float) - right_resized.astype(float))\n",
    "            symmetry_score = 1.0 / (1.0 + np.mean(difference))\n",
    "        else:\n",
    "            symmetry_score = 0.5\n",
    "       \n",
    "        return symmetry_score\n",
    "    def classify_gender_by_features(self, features):\n",
    "        \"\"\"Gender classification based on facial features\"\"\"\n",
    "        male_score = 0\n",
    "        female_score = 0\n",
    "       \n",
    "        # Feature 1: Aspect ratio (males tend to have wider faces)\n",
    "        if features['aspect_ratio'] > 0.85:\n",
    "            male_score += 0.3\n",
    "        else:\n",
    "            female_score += 0.3\n",
    "       \n",
    "        # Feature 2: Jaw variance (males tend to have more defined jaws)\n",
    "        if features['jaw_variance'] > features['upper_variance'] * 1.2:\n",
    "            male_score += 0.25\n",
    "        else:\n",
    "            female_score += 0.25\n",
    "       \n",
    "        # Feature 3: Edge density (facial hair, sharper features)\n",
    "        if features['edge_density'] > 0.15:\n",
    "            male_score += 0.2\n",
    "        else:\n",
    "            female_score += 0.2\n",
    "       \n",
    "        # Feature 4: Overall texture variance\n",
    "        total_variance = features['upper_variance'] + features['lower_variance']\n",
    "        if total_variance > 800:\n",
    "            male_score += 0.15\n",
    "        else:\n",
    "            female_score += 0.15\n",
    "       \n",
    "        # Feature 5: Histogram characteristics\n",
    "        if features['hist_peak'] < 120:  # Darker features\n",
    "            male_score += 0.1\n",
    "        else:\n",
    "            female_score += 0.1\n",
    "       \n",
    "        # Determine gender\n",
    "        if male_score > female_score:\n",
    "            confidence = min(0.95, 0.5 + male_score)\n",
    "            return 'Male', confidence\n",
    "        else:\n",
    "            confidence = min(0.95, 0.5 + female_score)\n",
    "            return 'Female', confidence\n",
    "   \n",
    "    def classify_age_by_features(self, features):\n",
    "        \"\"\"Age classification based on facial features\"\"\"\n",
    "        age_scores = {\n",
    "            'Child (0-12)': 0,\n",
    "            'Teen (13-19)': 0,\n",
    "            'Young Adult (20-30)': 0,\n",
    "            'Adult (31-50)': 0,\n",
    "            'Middle-aged (51-65)': 0,\n",
    "            'Senior (65+)': 0\n",
    "        }\n",
    "       \n",
    "        # Feature 1: Face size (children have smaller faces)\n",
    "        if features['face_area'] < 5000:\n",
    "            age_scores['Child (0-12)'] += 0.4\n",
    "        elif features['face_area'] < 8000:\n",
    "            age_scores['Teen (13-19)'] += 0.3\n",
    "            age_scores['Young Adult (20-30)'] += 0.2\n",
    "        else:\n",
    "            age_scores['Adult (31-50)'] += 0.2\n",
    "            age_scores['Young Adult (20-30)'] += 0.2\n",
    "       \n",
    "        # Feature 2: Wrinkle score (increases with age)\n",
    "        wrinkle_threshold = [100, 300, 600, 1000, 1500]\n",
    "        if features['wrinkle_score'] < wrinkle_threshold[0]:\n",
    "            age_scores['Child (0-12)'] += 0.3\n",
    "            age_scores['Teen (13-19)'] += 0.2\n",
    "        elif features['wrinkle_score'] < wrinkle_threshold[1]:\n",
    "            age_scores['Teen (13-19)'] += 0.3\n",
    "            age_scores['Young Adult (20-30)'] += 0.2\n",
    "        elif features['wrinkle_score'] < wrinkle_threshold[2]:\n",
    "            age_scores['Young Adult (20-30)'] += 0.3\n",
    "            age_scores['Adult (31-50)'] += 0.2\n",
    "        elif features['wrinkle_score'] < wrinkle_threshold[3]:\n",
    "            age_scores['Adult (31-50)'] += 0.3\n",
    "            age_scores['Middle-aged (51-65)'] += 0.2\n",
    "        elif features['wrinkle_score'] < wrinkle_threshold[4]:\n",
    "            age_scores['Middle-aged (51-65)'] += 0.3\n",
    "            age_scores['Senior (65+)'] += 0.2\n",
    "        else:\n",
    "            age_scores['Senior (65+)'] += 0.4\n",
    "       \n",
    "        # Feature 3: Skin smoothness (decreases with age)\n",
    "        if features['skin_smoothness'] > 0.7:\n",
    "            age_scores['Child (0-12)'] += 0.2\n",
    "            age_scores['Teen (13-19)'] += 0.2\n",
    "        elif features['skin_smoothness'] > 0.5:\n",
    "            age_scores['Teen (13-19)'] += 0.2\n",
    "            age_scores['Young Adult (20-30)'] += 0.2\n",
    "        elif features['skin_smoothness'] > 0.3:\n",
    "            age_scores['Young Adult (20-30)'] += 0.2\n",
    "            age_scores['Adult (31-50)'] += 0.2\n",
    "        else:\n",
    "            age_scores['Adult (31-50)'] += 0.15\n",
    "            age_scores['Middle-aged (51-65)'] += 0.2\n",
    "            age_scores['Senior (65+)'] += 0.2\n",
    "       \n",
    "        # Feature 4: Brightness variation (increases with age due to uneven skin)\n",
    "        if features['brightness_variation'] < 10:\n",
    "            age_scores['Child (0-12)'] += 0.1\n",
    "            age_scores['Teen (13-19)'] += 0.1\n",
    "        elif features['brightness_variation'] < 20:\n",
    "            age_scores['Teen (13-19)'] += 0.1\n",
    "            age_scores['Young Adult (20-30)'] += 0.1\n",
    "        else:\n",
    "            age_scores['Adult (31-50)'] += 0.1\n",
    "            age_scores['Middle-aged (51-65)'] += 0.1\n",
    "            age_scores['Senior (65+)'] += 0.1\n",
    "       \n",
    "        # Find the age range with highest score\n",
    "        best_age = max(age_scores, key=age_scores.get)\n",
    "        confidence = min(0.95, 0.4 + age_scores[best_age])\n",
    "       \n",
    "        return best_age, confidence\n",
    "   \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process single frame for gender detection\"\"\"\n",
    "        # Detect faces using Haar Cascade\n",
    "        faces = self.detect_faces_haar(frame)\n",
    "       \n",
    "        results = []\n",
    "       \n",
    "        for face_box in faces:\n",
    "            x1, y1, x2, y2, conf = face_box\n",
    "           \n",
    "            # Add some padding\n",
    "            padding = 10\n",
    "            y1 = max(0, y1 - padding)\n",
    "            y2 = min(frame.shape[0], y2 + padding)\n",
    "            x1 = max(0, x1 - padding)\n",
    "            x2 = min(frame.shape[1], x2 + padding)\n",
    "           \n",
    "            # Extract face region\n",
    "            face_crop = frame[y1:y2, x1:x2]\n",
    "           \n",
    "            if face_crop.size > 0:\n",
    "                try:\n",
    "                    # Classify gender and age\n",
    "                    gender, gender_conf, age_range, age_conf = self.analyze_facial_features(face_crop)\n",
    "                   \n",
    "                    if gender != 'Unknown':\n",
    "                        results.append({\n",
    "                            'box': [x1, y1, x2, y2],\n",
    "                            'gender': gender,\n",
    "                            'gender_confidence': float(gender_conf),\n",
    "                            'age_range': age_range,\n",
    "                            'age_confidence': float(age_conf),\n",
    "                            'face_conf': float(conf)\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in gender classification: {e}\")\n",
    "                    continue\n",
    "       \n",
    "        return results\n",
    "   \n",
    "    def process_frame_with_people(self, frame):\n",
    "        \"\"\"Alternative method: detect people first, then faces\"\"\"\n",
    "        people = self.detect_people_yolo(frame)\n",
    "        results = []\n",
    "       \n",
    "        for person_box in people:\n",
    "            x1, y1, x2, y2, person_conf = person_box\n",
    "           \n",
    "            # Extract person region\n",
    "            person_crop = frame[y1:y2, x1:x2]\n",
    "           \n",
    "            # Detect faces in person region\n",
    "            faces_in_person = self.detect_faces_haar(person_crop)\n",
    "           \n",
    "            for face in faces_in_person:\n",
    "                fx1, fy1, fx2, fy2, _ = face\n",
    "               \n",
    "                # Adjust coordinates to full frame\n",
    "                abs_fx1 = x1 + fx1\n",
    "                abs_fy1 = y1 + fy1\n",
    "                abs_fx2 = x1 + fx2\n",
    "                abs_fy2 = y1 + fy2\n",
    "               \n",
    "                # Extract face\n",
    "                face_crop = frame[abs_fy1:abs_fy2, abs_fx1:abs_fx2]\n",
    "               \n",
    "                if face_crop.size > 0:\n",
    "                    try:\n",
    "                        gender, gender_conf, age_range, age_conf = self.analyze_facial_features(face_crop)\n",
    "                       \n",
    "                        if gender != 'Unknown':\n",
    "                            results.append({\n",
    "                                'box': [abs_fx1, abs_fy1, abs_fx2, abs_fy2],\n",
    "                                'person_box': [x1, y1, x2, y2],\n",
    "                                'gender': gender,\n",
    "                                'gender_confidence': float(gender_conf),\n",
    "                                'age_range': age_range,\n",
    "                                'age_confidence': float(age_conf),\n",
    "                                'person_conf': float(person_conf)\n",
    "                            })\n",
    "                    except:\n",
    "                        continue\n",
    "       \n",
    "        return results\n",
    "   \n",
    "    def draw_results(self, frame, results):\n",
    "        \"\"\"Draw bounding boxes and gender/age labels\"\"\"\n",
    "        for result in results:\n",
    "            x1, y1, x2, y2 = result['box']\n",
    "            gender = result['gender']\n",
    "            gender_conf = result['gender_confidence']\n",
    "            age_range = result['age_range']\n",
    "            age_conf = result['age_confidence']\n",
    "           \n",
    "            # Draw face bounding box (gender color)\n",
    "            gender_color = self.colors.get(gender, (0, 255, 255))\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), gender_color, 2)\n",
    "           \n",
    "            # Draw age range indicator (small rectangle)\n",
    "            age_color = self.age_colors.get(age_range, (128, 128, 128))\n",
    "            cv2.rectangle(frame, (x2-20, y1), (x2, y1+20), age_color, -1)\n",
    "           \n",
    "            # Draw person box if available\n",
    "            if 'person_box' in result:\n",
    "                px1, py1, px2, py2 = result['person_box']\n",
    "                cv2.rectangle(frame, (px1, py1), (px2, py2), (128, 128, 128), 1)\n",
    "           \n",
    "            # Create labels\n",
    "            gender_label = f\"{gender}: {gender_conf:.2f}\"\n",
    "            age_label = f\"{age_range}: {age_conf:.2f}\"\n",
    "           \n",
    "            # Calculate label dimensions\n",
    "            gender_size = cv2.getTextSize(gender_label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "            age_size = cv2.getTextSize(age_label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n",
    "           \n",
    "            # Draw gender label background\n",
    "            cv2.rectangle(frame, (x1, y1-55), (x1+max(gender_size[0], age_size[0])+10, y1),\n",
    "                         gender_color, -1)\n",
    "           \n",
    "            # Draw gender label text\n",
    "            cv2.putText(frame, gender_label, (x1+5, y1-35),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "           \n",
    "            # Draw age label text\n",
    "            cv2.putText(frame, age_label, (x1+5, y1-15),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "       \n",
    "        return frame\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Initialize gender detection\n",
    "        print(\"Initializing Gender Detection System...\")\n",
    "        detector = GenderDetection()\n",
    "       \n",
    "        # Open camera\n",
    "        cap = cv2.VideoCapture(0)\n",
    "       \n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera. Trying with video file...\")\n",
    "            # You can replace this with a video file path\n",
    "            cap = cv2.VideoCapture('sample_video.mp4')\n",
    "           \n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open camera or video file\")\n",
    "            return\n",
    "       \n",
    "        print(\"System ready! Press 'q' to quit, 'p' to switch modes\")\n",
    "        use_people_detection = False\n",
    "       \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"End of video or camera error\")\n",
    "                break\n",
    "           \n",
    "            # Process frame\n",
    "            if use_people_detection:\n",
    "                results = detector.process_frame_with_people(frame)\n",
    "                mode_text = \"Mode: YOLO + Face Detection\"\n",
    "            else:\n",
    "                results = detector.process_frame(frame)\n",
    "                mode_text = \"Mode: Direct Face Detection\"\n",
    "           \n",
    "            # Draw results\n",
    "            output_frame = detector.draw_results(frame, results)\n",
    "           \n",
    "            # Add info text\n",
    "            info_text = f\"Faces: {len(results)} | Gender & Age Detection\"\n",
    "            cv2.putText(output_frame, info_text,\n",
    "                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "           \n",
    "            cv2.putText(output_frame, mode_text,\n",
    "                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "           \n",
    "            # Age range legend\n",
    "            legend_y = 90\n",
    "            cv2.putText(output_frame, \"Age Colors:\", (10, legend_y),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "           \n",
    "            for i, (age_range, color) in enumerate(detector.age_colors.items()):\n",
    "                y_pos = legend_y + 20 + (i * 15)\n",
    "                cv2.rectangle(output_frame, (10, y_pos-10), (25, y_pos), color, -1)\n",
    "                cv2.putText(output_frame, age_range.split('(')[0], (30, y_pos-2),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "           \n",
    "            cv2.putText(output_frame, \"Press 'p' to switch modes, 'q' to quit\",\n",
    "                       (10, frame.shape[0]-20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "           \n",
    "            # Display frame\n",
    "            cv2.imshow('Gender Detection with YOLO', output_frame)\n",
    "           \n",
    "            # Handle key presses\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('p'):\n",
    "                use_people_detection = not use_people_detection\n",
    "                print(f\"Switched to {'YOLO + Face' if use_people_detection else 'Direct Face'} detection mode\")\n",
    "       \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab48edf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
